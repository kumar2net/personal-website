# Copy this to .env for local development. Do NOT commit .env.

# AI Providers
# Gemini embeddings now require OAuth (API keys alone will 401). Prefer a service
# account via GCP_SERVICE_ACCOUNT_JSON; keep this only for legacy clients that
# still accept API keys.
GEMINI_API_KEY=YOUR_GEMINI_API_KEY
GEMINI_MODEL=gemini-1.5-pro-latest
OPENAI_API_KEY=YOUR_OPENAI_API_KEY
OPENAI_PROJECT=YOUR_OPENAI_PROJECT_ID
OPENAI_ORGANIZATION=YOUR_OPENAI_ORG_ID
OPENAI_MODEL=gpt-5.2
# Blog TTS (OpenAI Audio Speech)
# Prefer setting an ordered list (lets you drop in newly released TTS models without code changes):
# BLOG_TTS_MODELS=gpt-4o-mini-tts,tts-1
# Or set a single preferred model:
# BLOG_TTS_MODEL=gpt-4o-mini-tts
# Optional extra fallbacks to try before defaults:
# BLOG_TTS_FALLBACK_MODELS=tts-1-hd
# Latency tuning (smaller first chunk = faster time-to-first-audio):
# BLOG_TTS_FIRST_CHUNK_CHARS=900
# BLOG_TTS_MAX_CHUNK_CHARS=3600
# Disable streaming (forces buffered response):
# BLOG_TTS_STREAMING=false
CODEX_MODEL=gpt-5.2
CODEX_FALLBACK_MODELS=gpt-5.2-pro,gpt-5.2-mini,gpt-5.2-nano
CODEX_ISSUE_BATCH_SIZE=40
TLDR_PROVIDER=auto
TLDR_DEV_FAKE=0
TLDR_DEV_FALLBACK_ON_ERROR=1
TLDR_OPENAI_MODEL=gpt-5.2
TLDR_MAX_INPUT_CHARS=6000

# Google Cloud / Vertex AI
GCP_PROJECT_ID=YOUR_PROJECT_ID
GCP_LOCATION=us-central1
# For local dev you can paste minimal JSON or load from a file in your shell.
# The semantic search function now requires OAuth tokens in production, so set
# either GCP_SERVICE_ACCOUNT_JSON or the base64 helper below on Vercel/Netlify.
GCP_SERVICE_ACCOUNT_JSON={"type":"service_account","project_id":"YOUR_PROJECT","private_key_id":"...","private_key":"-----BEGIN PRIVATE KEY-----\\n...\\n-----END PRIVATE KEY-----\\n","client_email":"...","client_id":"...","token_uri":"https://oauth2.googleapis.com/token"}
# Hosts that refuse multiline env vars can use a base64 encoded payload.
# GCP_SERVICE_ACCOUNT_JSON_BASE64=BASE64_ENCODED_JSON_BLOB

# Vite example vars
VITE_NEWS_API_KEY=YOUR_NEWS_API_KEY
VITE_CLIMATIQ_API_KEY=YOUR_CLIMATIQ_API_KEY
VITE_TLDR_ENDPOINT=/api/tldr
VITE_TLDR_NETLIFY_PORT=8889
# Feature flags
# Turn on to show the unread posts bell/badge locally
VITE_FEATURE_UNREAD=on
